{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86197bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 01:39:36.826055: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-23 01:39:37.366329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-23 01:39:39.773852: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Numerical computing library for array operations and mathematical functions\n",
    "import numpy as np\n",
    "# Import the norm function for calculating vector/matrix norms (e.g., Euclidean distance)\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Serialization library for saving/loading Python objects to/from disk\n",
    "import pickle\n",
    "\n",
    "# Progress bar libraries for tracking loop iterations\n",
    "# tqdm - for command line progress bars\n",
    "# tqdm_notebook - for Jupyter notebook progress bars (deprecated, use tqdm.notebook instead)\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# Operating system interface for file and directory operations\n",
    "import os\n",
    "\n",
    "# Time-related functions for measuring execution time or adding delays\n",
    "import time\n",
    "\n",
    "# NOTE: From tf 2.X, the modules are available by referring to complete module tensorflow.keras.... unlike 1.x that used aliases like tf.keras...\n",
    "# Image preprocessing utilities from Keras\n",
    "from tensorflow.keras.preprocessing import image      #type: ignore\n",
    "\n",
    "\n",
    "# ResNet50 model architecture and its preprocessing function\n",
    "# ResNet50 - pre-trained convolutional neural network for image classification\n",
    "# preprocess_input - preprocesses images to match ResNet50's expected input format\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input    # type: ignore #typre:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69bc703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 01:39:40.816989: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize ResNet50 model using TF 2.X keras API\n",
    "model = ResNet50(weights='imagenet',  # Pre-trained ImageNet weights\n",
    "                 include_top=False,     # Exclude final classification layer for feature extraction\n",
    "                 input_shape=(224, 224, 3))  # Input dimensions (height, width, channels(RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca48b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function to extract features from an image using ResNet50 model can be typically used in any other instance of feature extraction.\n",
    "\n",
    "def extract_features(img_path, model):\n",
    "    \"\"\"\n",
    "    Extract normalized feature vector from an image using ResNet50.\n",
    "    \n",
    "    Args:\n",
    "        img_path: Path to the input image\n",
    "        model: Pre-loaded ResNet50 model\n",
    "    \n",
    "    Returns:\n",
    "        Normalized feature vector\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # Load and resize image to match model's expected input size\n",
    "    img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "    \n",
    "    # Convert PIL Image to numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Add batch dimension (model expects batch of images)\n",
    "    # Shape changes from (224, 224, 3) to (1, 224, 224, 3)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Apply ResNet50-specific preprocessing\n",
    "    # Normalizes pixel values according to ImageNet statistics\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    \n",
    "    # Extract features using the model\n",
    "    # In TF 2.X, model.predict() works in eager execution by default\n",
    "    features = model.predict(preprocessed_img)\n",
    "    \n",
    "    # Flatten the feature tensor to 1D vector\n",
    "    flattened_features = features.flatten()\n",
    "    \n",
    "    # L2 normalize the features for similarity comparisons\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    \n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44d9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "100352\n"
     ]
    }
   ],
   "source": [
    "# Check if everything is working as expected.\n",
    "features = extract_features('/home/vdv/Computer_Vision/dev/Practical-Deep-Learning-Book/sample-images/cat.jpg', model)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ee2b8",
   "metadata": {},
   "source": [
    "i) Features generated by ResNET. Each feature being a floating point between 0 & 1  \n",
    "100352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0737522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform fearure extraction for the enetire dataset.\n",
    "\n",
    "# Define a list of valid image file extensions to filter for\n",
    "extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively find all image files in a directory tree.\n",
    "    \n",
    "    Args:\n",
    "        root_dir: Root directory path to search for images\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (list of file paths, count of files found)\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the paths of found image files\n",
    "    file_list = []\n",
    "    \n",
    "    # Initialize a counter to track number of files found (starting at 0 for accurate count)\n",
    "    counter = 0\n",
    "    \n",
    "    # Get total number of directories for progress tracking\n",
    "    total_dirs = sum(1 for _, _, _ in os.walk(root_dir))\n",
    "    dir_counter = 0\n",
    "    \n",
    "    # Recursively walk through all directories starting from root_dir\n",
    "    # os.walk() returns: root (current dir path), directories (subdirs), filenames (files in current dir)\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        # Increment directory counter for progress tracking\n",
    "        dir_counter += 1\n",
    "        \n",
    "        # Iterate through each file in the current directory\n",
    "        for filename in filenames:\n",
    "            \n",
    "            # Check if the filename ends with any valid extension (case-sensitive)\n",
    "            if any(filename.endswith(ext) for ext in extensions):\n",
    "                \n",
    "                # If valid image, create full path by joining directory path with filename\n",
    "                full_path = os.path.join(root, filename)\n",
    "                \n",
    "                # Add the full path to the file_list\n",
    "                file_list.append(full_path)\n",
    "                \n",
    "                # Increment counter to track total images found\n",
    "                counter += 1\n",
    "                \n",
    "                # Print progress every 100 files (optional - remove if not needed)\n",
    "                if counter % 100 == 0:\n",
    "                    print(f\"Found {counter} images so far...\")\n",
    "        \n",
    "        # Print directory progress for large directory trees (optional)\n",
    "        if dir_counter % 10 == 0:\n",
    "            print(f\"Searched {dir_counter}/{total_dirs} directories...\")\n",
    "    \n",
    "    # Print final summary using the counter\n",
    "    print(f\"\\nSearch complete! Found {counter} image files in {dir_counter} directories.\")\n",
    "    \n",
    "    # Return both the file list and count for maximum utility\n",
    "    return file_list, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a1176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched 10/206 directories...\n",
      "Searched 20/206 directories...\n",
      "Searched 30/206 directories...\n",
      "Searched 40/206 directories...\n",
      "Searched 50/206 directories...\n",
      "Searched 60/206 directories...\n",
      "Searched 70/206 directories...\n",
      "Searched 80/206 directories...\n",
      "Searched 90/206 directories...\n",
      "Searched 100/206 directories...\n",
      "Found 100 images so far...\n",
      "Found 200 images so far...\n",
      "Found 300 images so far...\n",
      "Searched 110/206 directories...\n",
      "Found 400 images so far...\n",
      "Found 500 images so far...\n",
      "Found 600 images so far...\n",
      "Found 700 images so far...\n",
      "Found 800 images so far...\n",
      "Found 900 images so far...\n",
      "Found 1000 images so far...\n",
      "Found 1100 images so far...\n",
      "Found 1200 images so far...\n",
      "Searched 120/206 directories...\n",
      "Found 1300 images so far...\n",
      "Found 1400 images so far...\n",
      "Found 1500 images so far...\n",
      "Found 1600 images so far...\n",
      "Found 1700 images so far...\n",
      "Found 1800 images so far...\n",
      "Found 1900 images so far...\n",
      "Searched 130/206 directories...\n",
      "Found 2000 images so far...\n",
      "Found 2100 images so far...\n",
      "Found 2200 images so far...\n",
      "Found 2300 images so far...\n",
      "Found 2400 images so far...\n",
      "Found 2500 images so far...\n",
      "Searched 140/206 directories...\n",
      "Found 2600 images so far...\n",
      "Found 2700 images so far...\n",
      "Found 2800 images so far...\n",
      "Found 2900 images so far...\n",
      "Found 3000 images so far...\n",
      "Found 3100 images so far...\n",
      "Found 3200 images so far...\n",
      "Found 3300 images so far...\n",
      "Found 3400 images so far...\n",
      "Found 3500 images so far...\n",
      "Found 3600 images so far...\n",
      "Found 3700 images so far...\n",
      "Found 3800 images so far...\n",
      "Found 3900 images so far...\n",
      "Found 4000 images so far...\n",
      "Found 4100 images so far...\n",
      "Found 4200 images so far...\n",
      "Found 4300 images so far...\n",
      "Found 4400 images so far...\n",
      "Found 4500 images so far...\n",
      "Found 4600 images so far...\n",
      "Found 4700 images so far...\n",
      "Searched 150/206 directories...\n",
      "Found 4800 images so far...\n",
      "Found 4900 images so far...\n",
      "Found 5000 images so far...\n",
      "Found 5100 images so far...\n",
      "Found 5200 images so far...\n",
      "Found 5300 images so far...\n",
      "Found 5400 images so far...\n",
      "Found 5500 images so far...\n",
      "Found 5600 images so far...\n",
      "Searched 160/206 directories...\n",
      "Found 5700 images so far...\n",
      "Found 5800 images so far...\n",
      "Found 5900 images so far...\n",
      "Found 6000 images so far...\n",
      "Found 6100 images so far...\n",
      "Found 6200 images so far...\n",
      "Searched 170/206 directories...\n",
      "Found 6300 images so far...\n",
      "Found 6400 images so far...\n",
      "Found 6500 images so far...\n",
      "Found 6600 images so far...\n",
      "Found 6700 images so far...\n",
      "Found 6800 images so far...\n",
      "Found 6900 images so far...\n",
      "Found 7000 images so far...\n",
      "Found 7100 images so far...\n",
      "Found 7200 images so far...\n",
      "Found 7300 images so far...\n",
      "Searched 180/206 directories...\n",
      "Found 7400 images so far...\n",
      "Found 7500 images so far...\n",
      "Found 7600 images so far...\n",
      "Found 7700 images so far...\n",
      "Found 7800 images so far...\n",
      "Found 7900 images so far...\n",
      "Found 8000 images so far...\n",
      "Searched 190/206 directories...\n",
      "Found 8100 images so far...\n",
      "Found 8200 images so far...\n",
      "Found 8300 images so far...\n",
      "Found 8400 images so far...\n",
      "Found 8500 images so far...\n",
      "Found 8600 images so far...\n",
      "Found 8700 images so far...\n",
      "Searched 200/206 directories...\n",
      "Found 8800 images so far...\n",
      "Found 8900 images so far...\n",
      "Found 9000 images so far...\n",
      "Found 9100 images so far...\n",
      "\n",
      "Search complete! Found 9144 image files in 206 directories.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# path to the datasets\u001b[39;00m\n\u001b[32m      2\u001b[39m root_dir = \u001b[33m'\u001b[39m\u001b[33m/home/vdv/Computer_Vision/datasets/caltech-101\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m filenames = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_file_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "# Unpack the tuple to get both file_list and count\n",
    "file_list, count = get_file_list(root_dir)\n",
    "filenames = sorted(file_list)\n",
    "print(f\"Total images to process: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
